# 数据质量改进功能测试指南

本文档提供了完整的数据质量改进功能测试指南，帮助您验证所有改进功能是否正常工作。

## 目录

1. [测试环境准备](#测试环境准备)
2. [第一阶段：存储质量基础改进测试](#第一阶段存储质量基础改进测试)
3. [第二阶段：检索质量基础改进测试](#第二阶段检索质量基础改进测试)
4. [第三阶段：数据完整性检查测试](#第三阶段数据完整性检查测试)
5. [第四阶段：质量监控测试](#第四阶段质量监控测试)
6. [综合测试场景](#综合测试场景)
7. [常见问题排查](#常见问题排查)

---

## 测试环境准备

### 1. 确保服务运行

```bash
# 启动后端服务
cd cognee
uv run python -m cognee.api.client

# 启动前端服务（另一个终端）
cd cognee-frontend
npm run dev
```

### 2. 准备测试数据

建议使用包含以下内容的中文文档进行测试：
- 包含重复实体名称的文档（如"临时冻结"和"临时冻结措施"）
- 包含不同类型节点的文档（Entity、DocumentChunk等）
- 包含各种关系的文档（contains、is_a、is_part_of等）

### 3. 检查日志

测试过程中注意观察后端日志输出，所有质量改进功能都会记录详细的日志信息。

---

## 第一阶段：存储质量基础改进测试

### 测试1.1：实体名称规范化与合并

#### 测试步骤

1. **创建新数据集**
   - 访问前端：`http://localhost:3000`
   - 创建新数据集，命名为 `test_quality_1`

2. **上传测试文档**
   - 上传包含以下内容的文档：
     ```
     临时冻结不得超过四十八小时。金融机构在按照国务院反洗钱行政主管部门的要求采取临时冻结措施后四十八小时内，未接到国家有关机关继续冻结通知的，应当立即解除冻结。
     
     临时冻结措施是反洗钱调查的重要手段。临时冻结措施的实施需要经过严格的审批程序。
     ```
   - 注意：文档中包含"临时冻结"和"临时冻结措施"两个相似实体

3. **执行cognify**
   - 点击"认知化"按钮，等待处理完成

4. **验证结果**

   **方法1：查看日志**
   ```bash
   # 在后端日志中查找以下信息：
   # - "找到相似实体，合并: '临时冻结措施' -> '临时冻结'"
   # - "规范化实体名称"相关日志
   ```

   **方法2：查看图谱数据**
   - 在搜索页面查看生成的图谱
   - 验证"临时冻结"和"临时冻结措施"是否被合并为一个节点
   - 检查节点名称是否规范化（无多余空格、标点符号统一）

   **方法3：直接查询数据库**
   ```python
   # 可以使用Python脚本查询
   from cognee.infrastructure.databases.graph import get_graph_engine
   import asyncio
   
   async def check_entities():
       graph_engine = await get_graph_engine()
       # 查询实体节点
       # 验证相似实体是否合并
   
   asyncio.run(check_entities())
   ```

#### 预期结果

- ✅ 相似实体（如"临时冻结"和"临时冻结措施"）被合并
- ✅ 实体名称规范化（去除多余空格、统一标点）
- ✅ 合并后边的引用正确更新
- ✅ 日志中显示合并信息

#### 测试用例

| 测试项 | 输入 | 预期输出 |
|--------|------|----------|
| 空格处理 | "  临时冻结  " | "临时冻结" |
| 标点统一 | "临时冻结。" | "临时冻结" |
| 相似合并 | "临时冻结" 和 "临时冻结措施" | 合并为一个实体 |
| 大小写 | "TEMP" 和 "temp" | 合并为一个实体 |

---

### 测试1.2：实体质量评分

#### 测试步骤

1. **创建测试数据集**
   - 创建新数据集 `test_quality_2`

2. **上传包含不同质量实体的文档**
   ```
   高质量实体示例：
   董事长是董事会的负责人，由董事会全体董事过半数选举产生。董事长召集和主持董事会会议，检查董事会决议的实施情况。
   
   低质量实体示例（缺少描述）：
   某公司
   
   空名称实体示例：
   这是一个没有名称的实体描述。
   ```

3. **执行cognify并查看日志**
   ```bash
   # 在后端日志中查找：
   # - "低质量实体: '某公司' (质量分数: 0.xx)"
   # - "质量过滤: 原始实体数 X, 过滤后实体数 Y"
   ```

4. **验证质量分数**
   - 检查实体属性中是否包含 `quality_score` 字段
   - 验证低质量实体是否被过滤（如果启用了过滤）

#### 预期结果

- ✅ 每个实体都有质量分数（0-1之间）
- ✅ 完整实体（有名称、描述、类型）质量分数 ≥ 0.7
- ✅ 不完整实体质量分数 < 0.5
- ✅ 日志中显示质量分数信息

#### 质量分数计算验证

| 实体属性 | 质量分数范围 | 说明 |
|----------|--------------|------|
| 完整实体（名称+描述+类型+连接） | 0.8-1.0 | 高质量 |
| 部分属性缺失 | 0.5-0.8 | 中等质量 |
| 严重缺失（无名称或描述） | 0.0-0.5 | 低质量 |

---

### 测试1.3：关系合理性验证

#### 测试步骤

1. **创建测试数据集**
   - 创建新数据集 `test_quality_3`

2. **上传包含各种关系的文档**
   ```
   文档片段包含实体。
   实体属于实体类型。
   实体类型是概念。
   ```

3. **执行cognify并查看日志**
   ```bash
   # 在后端日志中查找：
   # - "过滤无效关系: ... 原因: ..."
   # - "跳过无效关系"相关日志
   ```

4. **验证关系有效性**
   - 检查图谱中的关系是否合理
   - 验证无效关系（如类型不匹配、循环关系）是否被过滤

#### 预期结果

- ✅ 有效关系（如 Entity --is_a--> EntityType）被保留
- ✅ 无效关系（如 DocumentChunk --is_a--> DocumentChunk）被过滤
- ✅ 循环关系被检测并过滤
- ✅ 日志中显示过滤信息

#### 关系验证规则测试

| 关系类型 | 源节点类型 | 目标节点类型 | 是否有效 |
|----------|------------|--------------|----------|
| contains | DocumentChunk | Entity | ✅ 有效 |
| is_a | Entity | EntityType | ✅ 有效 |
| is_a | DocumentChunk | DocumentChunk | ❌ 无效 |
| is_part_of | Entity | Entity | ✅ 有效 |
| belongs_to_set | Entity | NodeSet | ✅ 有效 |

---

### 测试1.4：空节点名称处理增强

#### 测试步骤

1. **创建测试数据集**
   - 创建新数据集 `test_quality_4`

2. **上传包含空名称节点的文档**
   - 上传一个包含DocumentChunk但名称可能为空的文档

3. **查看图谱可视化**
   - 在搜索页面查看生成的图谱
   - 验证所有节点都有可显示的标签

4. **验证标签生成逻辑**
   - 检查空名称节点是否使用了text或description作为标签
   - 验证标签长度是否合理（不超过30个字符）

#### 预期结果

- ✅ 所有节点都有非空标签
- ✅ 空名称节点使用text或description作为后备标签
- ✅ 标签长度合理（不超过30个字符+省略号）
- ✅ 前端显示正常，无空白节点

#### 标签生成优先级测试

| 节点属性 | 生成的标签 |
|----------|------------|
| name="董事长" | "董事长" |
| name="" text="董事会是公司的决策机构..." | "董事会是公司的决策机构..."（前30字符） |
| name="" text="" description="负责公司管理" | "负责公司管理" |
| name="" text="" description="" type="Entity" | "实体_xxxxxxxx"（类型+ID前8位） |

---

## 第二阶段：检索质量基础改进测试

### 测试2.1：检索结果质量评分

#### 测试步骤

1. **使用已有数据集**
   - 使用之前创建的包含丰富数据的数据集

2. **执行搜索**
   - 在搜索页面输入查询："临时冻结"
   - 观察返回的检索结果

3. **查看日志**
   ```bash
   # 在后端日志中查找：
   # - "质量过滤: 原始结果数 X, 过滤后结果数 Y (阈值: 0.6)"
   # - 质量评分相关信息
   ```

4. **验证结果排序**
   - 检查结果是否按相关性排序
   - 验证高质量结果排在前面

#### 预期结果

- ✅ 检索结果按质量分数排序
- ✅ 低质量结果（质量分数 < 0.6）被过滤
- ✅ 结果相关性明显提升
- ✅ 日志中显示质量过滤信息

#### 质量评分验证

执行以下搜索查询，验证结果质量：

| 查询 | 预期结果 |
|------|----------|
| "临时冻结" | 返回与"临时冻结"高度相关的结果 |
| "罚款" | 返回与"罚款"相关的结果，过滤无关节点 |
| "国际合作" | 返回与"国际合作"相关的结果 |

---

### 测试2.2：结果多样性控制

#### 测试步骤

1. **执行搜索**
   - 输入查询："反洗钱"
   - 观察返回的结果

2. **验证结果多样性**
   - 检查结果中是否包含不同类型的节点
   - 验证相似节点数量是否受限

3. **查看日志**
   ```bash
   # 在后端日志中查找：
   # - "多样性过滤: 原始结果数 X, 过滤后结果数 Y (类型分布: {...})"
   ```

#### 预期结果

- ✅ 结果包含不同类型的节点（Entity、DocumentChunk等）
- ✅ 每种类型的节点数量受限（最多2个相似节点）
- ✅ 结果更加多样化，避免过于集中
- ✅ 日志中显示类型分布信息

#### 多样性验证

执行搜索后，检查结果中的节点类型分布：

| 节点类型 | 预期数量 | 说明 |
|----------|----------|------|
| Entity | ≤ 2 | 每种类型最多2个 |
| DocumentChunk | ≤ 2 | 每种类型最多2个 |
| EntityType | ≤ 2 | 每种类型最多2个 |

---

### 测试2.3：相似度阈值优化

#### 测试步骤

1. **测试动态阈值调整**
   - 执行多个不同的搜索查询
   - 观察阈值是否根据结果数量自动调整

2. **查看日志**
   ```bash
   # 在后端日志中查找：
   # - "动态调整阈值: 0.5 -> 0.6 (结果数: X)"
   # - "动态调整阈值: 0.5 -> 0.4 (结果数: Y)"
   ```

3. **验证阈值效果**
   - 当结果太少时，阈值应该放宽（增加0.1）
   - 当结果太多时，阈值应该收紧（减少0.1）

#### 预期结果

- ✅ 当结果数 < 2*k 时，阈值自动放宽
- ✅ 当结果数 > 10*k 时，阈值自动收紧
- ✅ 阈值调整范围在 0.3-0.7 之间
- ✅ 日志中显示阈值调整信息

#### 阈值调整测试

| 初始阈值 | 结果数量 | 预期调整后阈值 |
|----------|----------|----------------|
| 0.5 | < 10 (k=5) | 0.6 (放宽) |
| 0.5 | > 50 (k=5) | 0.4 (收紧) |
| 0.5 | 10-50 (k=5) | 0.5 (不变) |

---

## 第三阶段：数据完整性检查测试

### 测试3.1：数据完整性检查

#### 测试步骤

1. **创建测试脚本**
   ```python
   # test_integrity.py
   import asyncio
   from uuid import UUID
   from cognee.modules.graph.utils.data_integrity_checker import (
       generate_integrity_report,
   )
   from cognee.infrastructure.databases.graph import get_graph_engine
   from cognee.modules.graph.cognee_graph.CogneeGraphElements import Node, Edge
   
   async def test_integrity(dataset_id: UUID):
       graph_engine = await get_graph_engine()
       nodes_data, edges_data = await graph_engine.get_graph_data()
       
       # 转换为Node和Edge对象
       nodes = [Node(n[0], n[1]) for n in nodes_data]
       edges = []  # 根据实际格式转换
       
       # 生成完整性报告
       report = generate_integrity_report(nodes, edges)
       
       print("完整性报告:")
       print(f"健康分数: {report['health_score']}")
       print(f"孤立节点: {len(report['issues']['orphan_nodes'])}")
       print(f"悬空边: {len(report['issues']['dangling_edges'])}")
       print(f"空名称节点: {len(report['issues']['empty_names'])}")
   
   # 运行测试
   # asyncio.run(test_integrity(dataset_id))
   ```

2. **执行完整性检查**
   - 运行测试脚本
   - 查看生成的报告

#### 预期结果

- ✅ 能够检测孤立节点
- ✅ 能够检测悬空边
- ✅ 能够检测缺失属性
- ✅ 能够计算健康分数（0-1之间）

#### 完整性指标

| 指标 | 目标值 | 说明 |
|------|--------|------|
| 健康分数 | ≥ 0.8 | 图谱整体健康度 |
| 孤立节点比例 | < 10% | 孤立节点占比 |
| 悬空边比例 | < 5% | 悬空边占比 |
| 空名称节点比例 | < 5% | 空名称节点占比 |

---

### 测试3.2：数据质量报告

#### 测试步骤

1. **创建测试脚本**
   ```python
   # test_quality_report.py
   import asyncio
   from uuid import UUID
   from cognee.modules.graph.utils.quality_report import generate_quality_report
   
   async def test_quality_report(dataset_id: UUID):
       report = await generate_quality_report(dataset_id)
       
       print("数据质量报告:")
       print(f"节点质量统计:")
       print(f"  - 总数: {report['summary']['node_quality']['total']}")
       print(f"  - 高质量: {report['summary']['node_quality']['high_quality']}")
       print(f"  - 中等质量: {report['summary']['node_quality']['medium_quality']}")
       print(f"  - 低质量: {report['summary']['node_quality']['low_quality']}")
       print(f"  - 平均质量分数: {report['summary']['node_quality']['average_quality_score']}")
       
       print(f"\n边质量统计:")
       print(f"  - 总数: {report['summary']['edge_quality']['total']}")
       print(f"  - 有效: {report['summary']['edge_quality']['valid']}")
       print(f"  - 无效: {report['summary']['edge_quality']['invalid']}")
       
       print(f"\n完整性统计:")
       print(f"  - 健康分数: {report['summary']['integrity']['health_score']}")
       print(f"  - 孤立节点: {report['summary']['integrity']['orphan_nodes']}")
       
       print(f"\n改进建议:")
       for rec in report['details']['recommendations']:
           print(f"  - {rec}")
   
   # 运行测试
   # asyncio.run(test_quality_report(dataset_id))
   ```

2. **执行质量报告生成**
   - 运行测试脚本
   - 查看生成的报告和建议

#### 预期结果

- ✅ 生成完整的质量报告
- ✅ 包含节点质量统计
- ✅ 包含边质量统计
- ✅ 包含完整性统计
- ✅ 提供改进建议

---

## 第四阶段：质量监控测试

### 测试4.1：检索质量指标

#### 测试步骤

1. **创建测试脚本**
   ```python
   # test_quality_metrics.py
   import asyncio
   from cognee.modules.search.utils.quality_metrics import (
       calculate_search_quality_metrics,
   )
   from cognee.modules.retrieval.utils.brute_force_triplet_search import (
       brute_force_triplet_search,
   )
   
   async def test_quality_metrics():
       query = "临时冻结"
       results = await brute_force_triplet_search(query, top_k=10)
       
       metrics = calculate_search_quality_metrics(
           query=query,
           results=results,
           answer="临时冻结不得超过四十八小时。",
       )
       
       print("检索质量指标:")
       print(f"  - 平均相关性分数: {metrics['avg_relevance']}")
       print(f"  - 多样性分数: {metrics['diversity_score']}")
       print(f"  - 覆盖率: {metrics['coverage']}")
       print(f"  - 精确度: {metrics['precision']}")
   
   # 运行测试
   # asyncio.run(test_quality_metrics())
   ```

2. **执行质量指标计算**
   - 运行测试脚本
   - 查看计算的指标

#### 预期结果

- ✅ 能够计算平均相关性分数
- ✅ 能够计算多样性分数
- ✅ 能够计算覆盖率
- ✅ 能够计算精确度
- ✅ 所有指标值在 0-1 之间

#### 质量指标目标

| 指标 | 目标值 | 说明 |
|------|--------|------|
| 平均相关性分数 | ≥ 0.7 | 结果平均相关性 |
| 多样性分数 | ≥ 0.3 | 结果类型多样性 |
| 覆盖率 | ≥ 0.8 | 查询实体覆盖率 |
| 精确度 | ≥ 0.85 | 检索结果精确度 |

---

## 综合测试场景

### 场景1：完整工作流测试

1. **创建数据集并上传文档**
   - 创建数据集 `test_comprehensive`
   - 上传包含丰富内容的文档（法律条文、公司制度等）

2. **执行cognify**
   - 观察处理过程
   - 检查日志中的质量改进信息

3. **执行搜索**
   - 输入多个不同的查询
   - 验证结果质量

4. **生成质量报告**
   - 运行质量报告脚本
   - 查看整体质量状况

5. **验证改进效果**
   - 对比改进前后的结果
   - 验证质量指标是否达到目标

### 场景2：边界情况测试

1. **空数据集测试**
   - 创建空数据集
   - 验证系统不会崩溃

2. **大量数据测试**
   - 上传大量文档
   - 验证性能和质量

3. **特殊字符测试**
   - 上传包含特殊字符的文档
   - 验证名称规范化是否正常

4. **极端查询测试**
   - 输入非常短的查询（1个字符）
   - 输入非常长的查询（100+字符）
   - 输入不相关的查询

---

## 常见问题排查

### 问题1：相似实体未合并

**可能原因：**
- 相似度阈值设置过高
- 实体名称规范化失败

**解决方法：**
1. 检查日志中的相似度计算
2. 调整 `find_similar_entities` 的阈值参数
3. 验证名称规范化是否正常工作

### 问题2：质量分数计算异常

**可能原因：**
- 实体属性缺失
- 计算函数异常

**解决方法：**
1. 检查实体属性是否完整
2. 查看日志中的错误信息
3. 验证质量评分函数逻辑

### 问题3：检索结果质量不佳

**可能原因：**
- 质量阈值设置不当
- 向量距离计算异常

**解决方法：**
1. 调整 `min_quality_score` 参数
2. 检查向量距离是否正确计算
3. 验证质量评分函数

### 问题4：完整性检查失败

**可能原因：**
- 图谱数据格式不匹配
- 节点/边对象转换错误

**解决方法：**
1. 检查图谱数据格式
2. 验证节点/边对象结构
3. 查看错误日志

---

## 测试检查清单

使用以下清单确保所有功能都已测试：

### 第一阶段
- [ ] 实体名称规范化功能正常
- [ ] 相似实体合并功能正常
- [ ] 实体质量评分功能正常
- [ ] 关系合理性验证功能正常
- [ ] 空节点名称处理功能正常

### 第二阶段
- [ ] 检索结果质量评分功能正常
- [ ] 结果多样性控制功能正常
- [ ] 动态阈值调整功能正常

### 第三阶段
- [ ] 数据完整性检查功能正常
- [ ] 质量报告生成功能正常

### 第四阶段
- [ ] 检索质量指标计算功能正常

### 综合
- [ ] 所有功能集成后正常工作
- [ ] 性能无明显下降
- [ ] 日志信息完整
- [ ] 错误处理正常

---

## 测试数据建议

### 推荐测试文档内容

1. **法律条文类**
   - 包含大量实体和关系
   - 适合测试实体合并和质量评分

2. **公司制度类**
   - 包含层次结构
   - 适合测试关系验证

3. **技术文档类**
   - 包含专业术语
   - 适合测试名称规范化

### 测试数据集大小建议

- **小型测试**：1-5个文档，100-500个实体
- **中型测试**：10-20个文档，1000-5000个实体
- **大型测试**：50+个文档，10000+个实体

---

## 性能测试

### 测试指标

1. **处理时间**
   - cognify处理时间不应显著增加（< 20%）
   - 检索响应时间不应显著增加（< 15%）

2. **内存使用**
   - 内存使用不应显著增加（< 10%）

3. **数据库查询**
   - 查询次数不应显著增加

### 性能基准

| 操作 | 改进前 | 改进后 | 允许增加 |
|------|--------|--------|----------|
| cognify (100实体) | 30s | < 36s | < 20% |
| 搜索响应 | 500ms | < 575ms | < 15% |
| 内存使用 | 500MB | < 550MB | < 10% |

---

## 总结

完成以上所有测试后，您应该能够：

1. ✅ 验证所有质量改进功能正常工作
2. ✅ 确认数据质量得到提升
3. ✅ 确认检索质量得到改善
4. ✅ 了解系统的质量状况
5. ✅ 获得改进建议

如果遇到任何问题，请查看日志文件或联系开发团队。

---

**测试完成后，建议：**
1. 记录测试结果
2. 收集性能数据
3. 整理发现的问题
4. 提出进一步优化建议


# -*- coding: utf-8 -*-
"""
人工评判版 RAGAS 评测
对每道题逐一人工打分（基于实际答案内容 vs Ground Truth）
评分标准：
  3 = 完全正确且全面（与Ground Truth高度一致）
  2 = 基本正确（核心事实正确，有少量遗漏）
  1 = 部分正确（有相关信息但不准确或不完整）
  0 = 错误/无法回答/答非所问
"""

# 从上次运行实际获取的答案（原样记录）
ACTUAL_ANSWERS = {
    "Q01": "本项目的主要目标是优化采购流程、提升信息化管理水平、对接NC系统、支持移动端操作、加强供应商管理与采购需求动态监控。",
    "Q02": "本项目系统最多允许2000名用户访问。",
    "Q03": "本项目工作说明书的文档版本号是1.1。",
    "Q04": "根据现有资料，未找到相关信息",
    "Q05": "本SOW文档的甲方是山东正和热电有限公司。",
    "Q06": "乙方是山东佳航智能科技有限公司。",
    "Q07": "AWS PaaS的版本号是6.4.GA，属于实例安装版、非集群模式。",
    "Q08": "根据现有资料，未找到关于项目付款里程碑划分的具体信息。上下文提到了里程碑计划（如项目准备、蓝图设计、系统建设、上线验收、上线支持），但未说明付款与这些里程碑的对应关系或付款比例。",
    "Q09": "甲方职责：负责硬件及基础环境建立维护、提供办公环境、协助集成接口联调、确保项目组专职人员有决策权、主导多家厂商协同。乙方职责：负责甲方技术人员培训、按SOW执行实施任务、参与全要素项目管理。",
    "Q10": "需求分析阶段的主要交付物包括：详细需求文档（采购申请、询比价等功能详细需求）、工作说明书（SOW）、采购需求与询比价全流程管理功能概述。",
    "Q11": "系统需要集成的外部系统包括：用友NC6.5（ERP系统）和钉钉。NC6.5集成涉及11类业务数据。",
    "Q12": "验收标准：1.没有严重缺陷及甲方不可接受的中等缺陷；2.各方已同意并拟定了处理遗留缺陷的期限及计划；3.系统上线验收以上线申请报告签批完成为标志。",
    "Q13": "服务范围包括：项目准备、蓝图设计、系统建设、上线验收、上线支持等阶段工作；流程实施、应用产品、系统集成、培训、上线后支持保障等内容。",
    "Q14": "供应商管理模块主要功能：1)供应商注册审核；2)供应商档案管理（基本信息/联系方式/银行账户/资质证书）；3)供应商分类管理；4)供应商评价（物流时效/产品质量等维度打分）。",
    "Q15": "采购申请流程：1.填写表单（物料信息、数量、需求日期）→2.查询库存（对接NC）→3.自动匹配流程分支→4.可选加急流程→5.支持平库操作→6.附件上传→流程完成进入台账，后续可发起询比价或招标。",
    "Q16": "根据现有资料，未找到相关信息",
    "Q17": "订单管理模块子功能：1)采购订单（合同导入、审批、推送NC）；2)到货通知单（由发货单自动生成，用于质检验收）。",
    "Q18": "客户端浏览器要求：A级浏览器（IE10+、Chrome35+、Firefox30+），PaaS控制台仅支持A级；IE须设为非兼容性模式；客户端分辨率不低于1024×768。",
    "Q19": "培训范围：AIE工程师培训、ADE工程师培训、AIE/ADE认证考试（乙方每季度公开课，免费参加，通过后颁发证书）。",
    "Q20": "合同审批流程步骤：发起合同审批（填报界面/自动带入供应商信息/上传附件）→审批流程执行→审批通过后生成合同台账。",
    "Q21": "合同变更管理流程：针对已签署合同内容进行修改、补充或终止，属于集团公司复杂业务流程，变更完成后生成新版本合同。",
    "Q22": "系统上线后运维支持期限：两个月，自上线之日起计算，包括问题修正和操作支持，方式含现场和远程；基础维保服务（MA）从合同签署满一年后开始。",
    "Q23": "供应商端填写发货单：在供应商平台订单管理模块→查询采购方订单→关联订单发起发货单→填写发货物料信息、规格型号、数量等关键字段。",
    "Q24": "项目验收两种形式：分项验收（需求设计验收、系统上线验收，按里程碑进行）和最终验收（系统上线运行3个月内）。",
    "Q25": "项目实施五个阶段：项目准备（目标定义）→蓝图设计（目标分解）→系统建设（目标实现）→上线验收（客户价值实现）→上线支持（投资收益最大化）。",
}

GROUND_TRUTH = {
    "Q01": "构建一套集成化采购管理系统，实现采购全生命周期数字化管理，提升采购效率与透明度，打通从需求申请到合同履行各环节，降低采购成本，优化供应商关系",
    "Q02": "不超过2000名用户（集团公司用户上限2000人）",
    "Q03": "版本1.1（初次V1.0，2025-03-25，编写人：闫伟鹏）",
    "Q04": "文档未明确给出项目计划完成日期（仅文档编写日期2025-03-25）",
    "Q05": "山东正和热电有限公司",
    "Q06": "山东佳航智能科技有限公司",
    "Q07": "AWS PaaS 6.4.GA（实例安装版，非集群）",
    "Q08": "文档未明确列出付款里程碑比例；仅有五阶段划分：项目准备/蓝图设计/系统建设/上线验收/上线支持",
    "Q09": "乙方：提供实施服务/培训甲方技术人员/按SOW执行；甲方：提供硬件环境/配合接口开发联调/确保专职人员有决策权/主导多厂商协同",
    "Q10": "文档未明确列出需求分析专项交付物清单；SOW本身含详细需求描述",
    "Q11": "用友NC6.5（ERP，11类业务数据集成）和钉钉（移动审批）",
    "Q12": "没有严重缺陷及甲方不可接受的中等缺陷；各方已同意拟定处理遗留缺陷期限；上线验收以上线申请报告签批为标志",
    "Q13": "采购管理系统实施服务：流程实施17个/AWS PaaS应用产品/用友NC6.5和钉钉集成/培训/上线后2个月支持/基础维保",
    "Q14": "供应商注册审核/供应商档案管理/供应商分类管理/供应商评价（物流时效/产品质量等维度）",
    "Q15": "填写采购需求申请→系统查询库存(NC)→自动匹配流程分支→可选加急→支持平库操作→附件→进入需求台账→发起询比价或招标",
    "Q16": "17个流程",
    "Q17": "采购订单（合同导入/审批/推送NC）、到货通知单（发货单自动生成）、验货申请单（仓库发起验货/审批/上传检验报告）",
    "Q18": "A级浏览器IE10+/Chrome35+/Firefox30+；IE须设为非兼容性模式；分辨率不低于1024×768；PaaS控制台仅支持A级",
    "Q19": "AIE/ADE工程师培训及认证考试（乙方每季度公开课，免费，通过后颁发证书）",
    "Q20": "发起合同审批→填写合同信息（自动带入供应商信息）→上传附件→审批执行→审批通过→生成合同台账",
    "Q21": "对已签合同修改/补充/终止，属集团公司复杂流程，变更完成生成新版本合同",
    "Q22": "上线后两个月内（现场+远程支持）；基础维保MA从合同签署满一年后开始",
    "Q23": "供应商平台→订单管理→查询采购方订单→关联订单发起发货单→填写物料信息/规格型号/数量",
    "Q24": "两种：分项验收（需求设计/上线验收，按里程碑）和最终验收（上线3个月内）",
    "Q25": "五个阶段：项目准备/蓝图设计/系统建设/上线验收/上线支持",
}

# 人工评判分数（3分制）及评判依据
HUMAN_SCORES = {
    # 格式：(准确性, 全面性, 说明)
    # 准确性：答案中的内容是否正确？
    # 全面性：关键信息是否都涵盖了？
    "Q01": (2, 2, "答案方向正确，但偏向优化层面（'优化采购流程/信息化管理水平'），GT强调'构建集成化平台/全生命周期管理'，核心目标稍有偏差，总体可接受"),
    "Q02": (3, 3, "完全正确且有引用依据"),
    "Q03": (3, 2, "版本号1.1正确，但缺少编写人和日期信息"),
    "Q04": (2, 2, "正确行为：文档确实没有项目计划完成日期，系统返回'未找到'是正确判断"),
    "Q05": (3, 3, "完全正确"),
    "Q06": (3, 3, "完全正确"),
    "Q07": (3, 3, "完全正确，附加了实例安装版/非集群说明"),
    "Q08": (2, 2, "正确指出文档无具体付款里程碑，提供了相关的阶段信息作为补充"),
    "Q09": (3, 2, "甲乙方职责描述准确，但GT中乙方职责'按SOW执行'体现不够突出"),
    "Q10": (1, 1, "GT明确说明文档无专项交付物列表；系统给出了近似答案但与实际文档内容不完全一致"),
    "Q11": (3, 3, "完全正确：用友NC6.5(11类数据)+钉钉"),
    "Q12": (3, 3, "完全正确：三条验收标准均覆盖"),
    "Q13": (2, 1, "基本正确，但遗漏了关键信息'17个流程'和'2个月上线支持'"),
    "Q14": (3, 3, "完全正确：四大功能均覆盖"),
    "Q15": (3, 3, "步骤完整正确"),
    "Q16": (0, 0, "FAIL：返回'未找到相关信息'，正确答案是17个流程"),
    "Q17": (2, 2, "采购订单/到货通知单正确，但遗漏了'验货申请单'（GT第三个子功能）"),
    "Q18": (3, 3, "完全正确：浏览器要求/IE非兼容/分辨率均覆盖"),
    "Q19": (3, 3, "完全正确"),
    "Q20": (3, 2, "步骤正确，但遗漏了'从推荐供应商台账自动带入信息'的细节"),
    "Q21": (3, 2, "基本正确，关键特征'生成新版本合同'已覆盖"),
    "Q22": (3, 3, "完全正确：两个月支持+维保一年后"),
    "Q23": (3, 3, "完全正确，步骤清晰"),
    "Q24": (3, 3, "完全正确"),
    "Q25": (3, 3, "完全正确，五个阶段及子标题均准确"),
}

def run_manual_evaluation():

    print("=" * 70)
    print("RAG 系统人工精确评判报告（RAGAS 标准）")
    print("=" * 70)
    print(f"评分标准: 3=完全正确且全面 / 2=基本正确 / 1=部分正确 / 0=错误/无法回答")
    print()

    total_accuracy = 0
    total_completeness = 0
    perfect = 0
    fail_count = 0
    results = []

    for qid in sorted(HUMAN_SCORES.keys()):
        acc, comp, note = HUMAN_SCORES[qid]
        avg = (acc + comp) / 2
        pct = avg / 3 * 100

        status = "✓✓" if avg >= 2.5 else ("✓" if avg >= 1.5 else ("△" if avg >= 0.5 else "✗"))
        print(f"[{qid}] [{status}] 准确={acc}/3 全面={comp}/3 综合={avg:.1f}/3 ({pct:.0f}%)")
        print(f"  查询: {list(v for k,v in [('Q01','本项目的主要目标是什么？'),('Q02','系统最多允许多少名用户访问？'),('Q03','文档版本号是多少？'),('Q04','计划完成日期？'),('Q05','甲方是谁？'),('Q06','乙方是谁？'),('Q07','AWS PaaS版本号？'),('Q08','付款里程碑？'),('Q09','甲乙双方职责？'),('Q10','需求分析交付物？'),('Q11','集成哪些外部系统？'),('Q12','验收标准？'),('Q13','服务范围？'),('Q14','供应商管理模块功能？'),('Q15','采购申请流程？'),('Q16','共实施多少流程？'),('Q17','订单管理子功能？'),('Q18','浏览器要求？'),('Q19','培训范围？'),('Q20','合同审批步骤？'),('Q21','合同变更流程？'),('Q22','运维支持期限？'),('Q23','如何填写发货单？'),('Q24','验收形式？'),('Q25','实施总体阶段？')] if k==qid)[0]}")
        print(f"  评判: {note}")
        print()

        total_accuracy += acc
        total_completeness += comp
        if avg >= 2.5:
            perfect += 1
        if avg < 1.0:
            fail_count += 1
        results.append((qid, acc, comp, avg, note))

    n = len(HUMAN_SCORES)
    overall_acc = total_accuracy / (n * 3) * 100
    overall_comp = total_completeness / (n * 3) * 100
    overall_avg = (overall_acc + overall_comp) / 2

    print("=" * 70)
    print(f"汇总结果 ({n} 题)")
    print(f"  准确性均值:   {overall_acc:.1f}%  ({total_accuracy}/{n*3})")
    print(f"  全面性均值:   {overall_comp:.1f}%  ({total_completeness}/{n*3})")
    print(f"  综合精度:     {overall_avg:.1f}%")
    print(f"  完全正确题数: {perfect}/{n} ({perfect/n*100:.0f}%)")
    print(f"  完全失败题数: {fail_count}/{n}")
    print("=" * 70)

    # 问题题目清单
    problem_items = [(qid, acc, comp, avg, note) for qid, acc, comp, avg, note in results if avg < 2.0]
    if problem_items:
        print(f"\n需要改进的题目（综合分 < 2/3 = 67%）：")
        for qid, acc, comp, avg, note in sorted(problem_items, key=lambda x: x[3]):
            print(f"  [{qid}] {avg:.1f}/3 | {note[:60]}")

    return overall_avg

if __name__ == "__main__":
    score = run_manual_evaluation()
    print(f"\n结论: {'达标(≥95%)' if score >= 95 else f'未达标(当前{score:.1f}%，目标95%)，需要继续优化'}")
